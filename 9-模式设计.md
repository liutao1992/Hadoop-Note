关于分区

Hive中分区的功能分词有用。这是因为Hive通常要对输入进行全盘扫描，来满足查询条件。通过创建很多的分区确实可以优化一些查询，但同时可能会对其他一些重要的查询不利。

HDFS用于设计存储数百万的大文件，而非数十亿的小文件。使用过多的分区可能导致的一个问题就是会创建大量的非必须的Hadoop文件和文件夹。一个分区就对应着一个包含有多个文件的文件夹。如果指定的表存在着数百个分区，那么可能每天都会创建好几万个文件。如果保持这样的表好多年，那么最终就会超出NameNode对系统云数据信息的处理能力。因为NameNode必须要将所有的系统文件的元数据信息保存在内存中。虽然每个文件只需要少量字节大小的元数据（大约150字节/文件），但是这样也会限制一个HDFS实例所能管理的文件总数的上限。

MapReduce会将一个任务（job）转换成多个任务（task）。默认情况下，每个task都是一个新的JVM实例，都需要开启和销毁。

因此，一个理想的分区方案不应该导致产生太多的分区和文件夹目录，并且每个目录下的文件应该足够得大，应该是文件系统中块大小的若干倍。

按时间范围进行分区的一个好的策略就是按照不同的时间粒度来确定合适大小的数据积累量，而且安装这个时间粒度。随着时间的推移，分区数量的增长是“均匀的”，而且每个分区下包含的文件大小至少是文件系统中块的大小或块大小的数倍。这个平衡可以保持分区足够大，从而优化一般情况下查询查询的数据吞吐量。